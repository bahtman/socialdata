{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "We have chosen a dataset with country wide traffic accidents in the US. This dataset has a lot of data that we can explore, while using the multitude of the tools we have taught in the course. It also opens up the possibility to do advanced analysis. Our goal is to show the user how dangerous it can be to drive during bad/extreme weather conditions, using interactive tools. We believe that by doing this, the user is more entertained and invested in the findings of our analysis.\n",
    "\n",
    "# Basic stats\n",
    "\n",
    "Before starting the analysis, we have had to remove some of the non-important features of our dataset. We did this by removing 26 attributes. Furthermore some cleanup was needed to remove n/a values. After cleanup, our dataset is 350MB large and contains 20 attributes. As the data is from an american source, we change all units from empirial to metric units.\n",
    "\n",
    "To determine how weather conditions affect car accidents we will have a main focus on the severity of the car accidents, which is a attribute ranging from 1-4 (4 being the most catastrophic). Our main focus will therefore be on how weather increases or decreases the severity of accidents. \n",
    "\n",
    "\n",
    "MANGLER: \"Write a short section that discusses the dataset stats, containing key points/plots from your exploratory data analysis.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing data\n",
    "data = pd.read_csv(\"data/US_Accidents_Dec20.csv\")\n",
    "CleanedData = data.drop(['Number','Distance(mi)','Airport_Code','Street','Side','Country','Amenity','Bump','Crossing','Give_Way','Junction','No_Exit','Railway','Roundabout','Station','Stop','Traffic_Calming','Traffic_Signal','Turning_Loop','Sunrise_Sunset','Civil_Twilight','Nautical_Twilight','Astronomical_Twilight', 'End_Lat','End_Lng', 'Wind_Direction'],axis='columns', inplace=False)\n",
    "CleanedData.info()\n",
    "CleanedData = CleanedData.dropna()\n",
    "CleanedData['Temperature'] = CleanedData['Temperature(F)'].apply(lambda x: (x-32) * (5/9))\n",
    "CleanedData['Wind_Chill'] = CleanedData['Wind_Chill(F)'].apply(lambda x: (x-32) * (5/9))\n",
    "CleanedData['Visibility'] = CleanedData['Visibility(mi)'].apply(lambda x: x*1.609344)\n",
    "CleanedData['Wind_Speed'] = CleanedData['Wind_Speed(mph)'].apply(lambda x: x*1.609344*1000/3600)\n",
    "CleanedData['Precipitation'] = CleanedData['Precipitation(in)'].apply(lambda x: x*25.4)\n",
    "CleanedData['Pressure'] = CleanedData['Pressure(in)'].apply(lambda x: x*33.86)\n",
    "\n",
    "df = CleanedData"
   ]
  },
  {
   "source": [
    "## Creating KPI's\n",
    "\n",
    "To understand the dataset better, we create some key point indicators. This includes the most important continuous attributes of the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_attributes = [\"Severity\",\"Temperature\",\"Wind_Chill\",\"Humidity(%)\",\"Pressure\",\"Visibility\",\"Wind_Speed\",\"Precipitation\"]\n",
    "\n",
    "KPI = pd.DataFrame(data={'KPI': ['Mean']})\n",
    "\n",
    "for i in key_attributes:\n",
    "    KPI[i] = df[i].mean()\n",
    "\n",
    "print(KPI)"
   ]
  },
  {
   "source": [
    "Now that we have created some basic key point indicators from our dataset, we would like to get an insight on how the different weather conditions affect the severity of the car accidents. One insight we get from the mean values is that the Temperature and Wind_Chill are quite similar, and thefore moving forward we removed Wind_Chill. \n",
    "\n",
    "We can make some basic exploratory data analysis, by calculating the mean for the same attributes, but focusing on specific values of severity. Specifically we would like to analyse on the extremes, which is severity 1 and severity 4."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_attributes = [\"Severity\",\"Temperature\",\"Humidity(%)\",\"Pressure\",\"Visibility\",\"Wind_Speed\",\"Precipitation\"]\n",
    "\n",
    "KPI = pd.DataFrame(data={'KPI': ['Mean']})\n",
    "\n",
    "for i in key_attributes:\n",
    "    KPI[i] = df[df[\"Severity\"]==1][i].mean()\n",
    "print(KPI)\n",
    "print(\"-----------------------------------------------------------------------------------------------------\")\n",
    "KPI = pd.DataFrame(data={'KPI': ['Mean']})\n",
    "for i in key_attributes:\n",
    "    KPI[i] = df[df[\"Severity\"]==4][i].mean()\n",
    "print(KPI)"
   ]
  },
  {
   "source": [
    "The idea is now to find which attributes is the most different between severity 1 and severity 4. These are the attributes we wish to use when going deeper into our data analysis.\n",
    "\n",
    "* Temperature is clearly lower on severity 4, so we keep that for further analysis.\n",
    "* Humidity is clearly higher on severity 4, so we keep that for further analysis.\n",
    "* We see no significant changes in the mean of pressure, so we do not use it for further analysis\n",
    "* Visibility is clearly lower on severity 4, so we keep that for further analysis.\n",
    "* Wind speed is clearly lower on severity 4, so we keep that for further analysis. One thing to note, is that this indicates that higher wind speeds reduces the severity, which we did not expect.\n",
    "* Precipation is only slightly higher between the two severities. This can be caused by having a large amount of cases, where there is no precipitation at all, so we would like to make an extra check on this attribute."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "count = df[\"Precipitation(in)\"]==0\n",
    "print(\"Amount of cases where there is no precipation at all in the dataset is:\", round(100*(count.sum()/len(count)),2),\"%\")\n",
    "print(\"------------------------------------------------\")\n",
    "KPI = pd.DataFrame(data={'KPI': ['Mean']})\n",
    "KPI[\"Severity\"] = df[df[\"Precipitation(in)\"]>0][\"Severity\"].mean()\n",
    "print(KPI)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In 91.25% of all car accidents in the dataset, there is no precipitation at all. In the rest of the 8.75% cases, the mean severity 2.29, which is only 0.09 higher than the mean of the whole dataset. As this is only a slight increase, and it only effects 8.75% of all car accidents in the US, we decide not to include precipitation in our deeper data analysis.\n",
    "\n",
    "The attributes we decided was best for our data analysis are:\n",
    "* Temperature\n",
    "* Humidity\n",
    "* Visiblity\n",
    "* Wind Speed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Data Analysis\n",
    "\n",
    "Describe your data analysis and explain what you've learned about the dataset.\n",
    "If relevant, talk about your machine-learning.\n",
    "\n",
    "Hvad vi har lært må vi nok vente lidt med - kan vi måske køre løs på i morgen (Kjær og mus) - tænker dette bliver det primære afsnit i \"explainer_notebook\". \n",
    "\n",
    "After analysing how different weather conditions affect traffic accidents across the US, we though it would be relevant to create a model, which can predict the serverity of a accident, given different weather conditions. To do so we performed some data engineering, by decoding the \"weather condition\" to a numeric value sympolizing one of the 111 conditions. Next we used a supervised learning classifier (logistic regression) to predidict the severity of an accident for future accident. This was possible as we had labeled data, where the severity were out labels. \n",
    "\n",
    "\n",
    "# Genre\n",
    "\n",
    "So far har jeg skrevet lidt om highlighting, ordering, interactivity og messaging. (mangler visual structuring og transition guidance)\n",
    "\n",
    "To tell our story we used some different tools. We used the tool zooming from the \"Visual Narrative - highlighting\" type tool. This is because at first our data has a huge scope, and a zoom is quite usefull to tell stories in a way more local and precise manner. \n",
    "\n",
    "The narrative structure used to lead the reader is to folded. From the type \"ordering\" both \"linear\" and \"random access\" was used random access as we would like the reader to investigate the data and the story it tells by one self, using the tools that we have prepared for the reader, but in order to also help the reader to reach the conclusion we made, and see our entire analysis we have also prepared a \"linear\" storytelling, used to lead the reader through our entire thoughtprocess.   \n",
    "\n",
    "\n",
    "The tools mentioned to let the reader exploit the data and learn the story it tells, we have created tools of the interactivity type: \"navigative buttons, filter/selection/seach\n",
    "\n",
    "In order to get the story across to the reader the Narrative structure messaging tools like headlines/captions and annotations have been used.\n",
    "\n",
    "# Visualizations\n",
    "\n",
    "Explain the visualizations you've chosen.\n",
    "Why are they right for the story you want to tell?\n",
    "\n",
    "We have chosen to use a mix of different plots, where our most important visualizations are when using geodata. This type of plot is easy to understand and therefore a good choice, because we try to cater to all type of users.\n",
    "\n",
    "We will create a userbased interface, which will enables the user to investigate the data by ones self. But also to help the user understand the data we will display the data in a \"cartoon\" type, telling our story of the analysis, in order to inspire the user, for how the data can be investigated.\n",
    "\n",
    "# Discussion\n",
    "Think critically about your creation\n",
    "What went well?,\n",
    "What is still missing? What could be improved?, Why?\n",
    "\n",
    "\n",
    "# Contributions\n",
    "\n",
    "Who did what?\n",
    "You should write (just briefly) which group member was the main responsible for which elements of the assignment. (I want you guys to understand every part of the assignment, but usually there is someone who took lead role on certain portions of the work. That's what you should explain).\n",
    "It is not OK simply to write \"All group members contributed equally\".\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd058d4daf3a05f46a277e8de577487214c4b87a3fcea5d135f57027d19dbb88902",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}